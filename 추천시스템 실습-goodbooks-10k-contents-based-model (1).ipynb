{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Goodbooks-10k \n",
    "- Link : https://www.kaggle.com/zygmunt/goodbooks-10k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## base line -> 통계기반의 모델 : 인기순으로 추천 or 평점이 높은 책 추천"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotnine \n",
    "from plotnine import *\n",
    "import os, sys, gc\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['books.csv', 'book_tags.csv', 'credits.csv', 'keywords.csv', 'links.csv', 'links_small.csv', 'movies_metadata.csv', 'ratings.csv', 'ratings2.csv', 'ratings_small.csv', 'sample_book.xml', 'tags.csv', 'test.csv', 'to_read.csv', 'train.csv']\n"
     ]
    }
   ],
   "source": [
    "path = 'C:/data/archive/'\n",
    "print(os.listdir(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = pd.read_csv(path + \"books.csv\")\n",
    "book_tags = pd.read_csv(path + \"book_tags.csv\")\n",
    "train = pd.read_csv(path + \"train.csv\")\n",
    "test = pd.read_csv(path + \"test.csv\")\n",
    "tags = pd.read_csv(path + \"tags.csv\")\n",
    "to_read = pd.read_csv(path + \"to_read.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['book_id'] = train['book_id'].astype(str)\n",
    "test['book_id'] = test['book_id'].astype(str)\n",
    "books['book_id'] = books['book_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인기순으로 200권 추천\n",
    "\n",
    "popular_rec_model = books.sort_values(by='books_count', ascending=False)['book_id'].values[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0949cce61d874156aafe4871183ec739",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=53424.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sol = test.groupby(['user_id'])['book_id'].agg({'unique'}).reset_index()\n",
    "gt = {}\n",
    "for user in tqdm(sol['user_id'].unique()): \n",
    "    gt[user] = list(sol[sol['user_id'] == user]['unique'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_df = pd.DataFrame()\n",
    "rec_df['user_id'] = train['user_id'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF를 이용한 Contents Based Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 9019)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(books['title'])\n",
    "print(tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cosine_matrix = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "cosine_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# book title와 id를 매핑할 dictionary를 생성해줍니다. \n",
    "book2id = {}\n",
    "for i, c in enumerate(books['title']): book2id[i] = c\n",
    "\n",
    "# id와 book title를 매핑할 dictionary를 생성해줍니다. \n",
    "id2book = {}\n",
    "for i, c in book2id.items(): id2book[c] = i\n",
    "    \n",
    "# book_id와 title를 매핑할 dictionary를 생성해줍니다.\n",
    "bookid2book = {}\n",
    "for i, j in zip(books['title'].values, books['book_id'].values):\n",
    "    bookid2book[i] = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              The Hunger Games (The Hunger Games, #1)\n",
       "1    Harry Potter and the Sorcerer's Stone (Harry P...\n",
       "2                              Twilight (Twilight, #1)\n",
       "3                                To Kill a Mockingbird\n",
       "4                                     The Great Gatsby\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books['title'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The Twilight Saga (Twilight, #1-4)', 0.920347418277986),\n",
       " ('The Twilight Collection (Twilight, #1-3)', 0.8786339079447184),\n",
       " ('The Twilight Saga Complete Collection  (Twilight, #1-4 + 3.5)',\n",
       "  0.7697532056304309),\n",
       " ('Twilight and History', 0.7465001575650626),\n",
       " ('The Twilight Saga: The Official Illustrated Guide (Twilight, #4.5)',\n",
       "  0.7045174300631831),\n",
       " ('Twilight Eyes', 0.6770737331426326),\n",
       " ('Twilight (The Mediator, #6)', 0.6377631333498953),\n",
       " ('New Moon (Twilight, #2)', 0.6185575138625542),\n",
       " ('Eclipse (Twilight, #3)', 0.612819563854136),\n",
       " ('The Servants of Twilight', 0.5837817298466093)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = id2book['Twilight (Twilight, #1)']  \n",
    "sim_scores = [(book2id[i], c) for i, c in enumerate(cosine_matrix[idx]) if i != idx] \n",
    "sim_scores = sorted(sim_scores, key = lambda x: x[1], reverse=True)\n",
    "sim_scores[0:10] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. 학습셋에서 제목이 있는 경우에 대해서만 진행\n",
    "1. 각 유저별로 읽은 책의 목록을 수집 \n",
    "2. 읽은 책과 유사한 책 추출 \n",
    "3. 모든 책에 대해서 유사도를 더한 값을 계산 \n",
    "4. 3에서 유사도가 가장 높은 순서대로 추출 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4893</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>8855</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9049</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3273</td>\n",
       "      <td>Moloka'i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>8072</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id book_id     title\n",
       "0        1    4893       NaN\n",
       "1        2    8855       NaN\n",
       "2        3    9049       NaN\n",
       "3        4    3273  Moloka'i\n",
       "4        5    8072       NaN"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.merge(train, books[['book_id', 'title']], how='left', on='book_id')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>title</th>\n",
       "      <th>idx2title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>3273</td>\n",
       "      <td>Moloka'i</td>\n",
       "      <td>1215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>4588</td>\n",
       "      <td>Extremely Loud and Incredibly Close</td>\n",
       "      <td>248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>1519</td>\n",
       "      <td>The Oresteia  (Ορέστεια, #1-3)</td>\n",
       "      <td>4148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>3711</td>\n",
       "      <td>White Teeth</td>\n",
       "      <td>1004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>4138</td>\n",
       "      <td>Naked</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id book_id                                title  idx2title\n",
       "0        4    3273                             Moloka'i       1215\n",
       "1        7    4588  Extremely Loud and Incredibly Close        248\n",
       "2        7    1519       The Oresteia  (Ορέστεια, #1-3)       4148\n",
       "3        7    3711                          White Teeth       1004\n",
       "4        7    4138                                Naked        343"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0. 학습셋에서 제목이 있는 경우에 대해서만 진행\n",
    "tf_train = train[train['title'].notnull()].reset_index(drop=True)\n",
    "tf_train['idx2title'] = tf_train['title'].apply(lambda x: id2book[x])\n",
    "tf_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2title2book = {}\n",
    "for i, j in zip(tf_train['idx2title'].values, tf_train['book_id'].values):\n",
    "    idx2title2book[i] = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 248, 4148, 1004,  343], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. 각 유저별로 읽은 책의 목록을 수집 \n",
    "user = 7\n",
    "read_list = tf_train.groupby(['user_id'])['idx2title'].agg({'unique'}).reset_index()\n",
    "seen = read_list[read_list['user_id'] == user]['unique'].values[0]\n",
    "seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. 읽은 책과 유사한 책 추출 \n",
    "## 343번째 책과 다른 책들간의 유사도 \n",
    "cosine_matrix[343]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 읽은 책과 유사한 책 추출 \n",
    "total_cosine_sim = np.zeros(len(book2id))\n",
    "for book_ in seen: \n",
    "    # 3. 모든 책에 대해서 유사도를 더한 값을 계산 \n",
    "    # 343번째 책과 248의 유사도가 모두 결합된 유사도\n",
    "    total_cosine_sim += cosine_matrix[book_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4809, 0.793036327171204),\n",
       " (6199, 0.6915730356677104),\n",
       " (3194, 0.6607508855409738),\n",
       " (1570, 0.6390974315343301),\n",
       " (7393, 0.5820260477746269)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. 3에서 유사도가 가장 높은 순서대로 추출\n",
    "sim_scores = [(i, c) for i, c in enumerate(total_cosine_sim) if i not in seen] # 자기 자신을 제외한 영화들의 유사도 및 인덱스를 추출 \n",
    "sim_scores = sorted(sim_scores, key = lambda x: x[1], reverse=True) # 유사도가 높은 순서대로 정렬 \n",
    "sim_scores[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Naked and the Dead'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book2id[4809]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'12467'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bookid2book[book2id[4809]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    4,     7,    14, ..., 53419, 53420, 53423], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_train['user_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>title</th>\n",
       "      <th>idx2title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>3273</td>\n",
       "      <td>Moloka'i</td>\n",
       "      <td>1215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>4588</td>\n",
       "      <td>Extremely Loud and Incredibly Close</td>\n",
       "      <td>248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>1519</td>\n",
       "      <td>The Oresteia  (Ορέστεια, #1-3)</td>\n",
       "      <td>4148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>3711</td>\n",
       "      <td>White Teeth</td>\n",
       "      <td>1004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>4138</td>\n",
       "      <td>Naked</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id book_id                                title  idx2title\n",
       "0        4    3273                             Moloka'i       1215\n",
       "1        7    4588  Extremely Loud and Incredibly Close        248\n",
       "2        7    1519       The Oresteia  (Ορέστεια, #1-3)       4148\n",
       "3        7    3711                          White Teeth       1004\n",
       "4        7    4138                                Naked        343"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7380d401cf6a4710841c8a523f25011c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=53382.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## 전체 영화에 대해서 진행 \n",
    "total_rec_list = {}\n",
    "\n",
    "read_list1 = train.groupby(['user_id'])['book_id'].agg({'unique'}).reset_index()\n",
    "read_list2 = tf_train.groupby(['user_id'])['idx2title'].agg({'unique'}).reset_index()\n",
    "\n",
    "for user in tqdm(train['user_id'].unique()):\n",
    "    rec_list = []\n",
    "        \n",
    "    # 만약 TF-IDF 소속의 추천대상이라면 Contents 기반의 추천 \n",
    "    if user in tf_train['user_id'].unique():\n",
    "        # 1. 각 유저별로 읽은 책의 목록을 수집 \n",
    "        seen = read_list2[read_list2['user_id'] == user]['unique'].values[0]\n",
    "        # 2. 읽은 책과 유사한 책 추출 \n",
    "        total_cosine_sim = np.zeros(len(book2id))\n",
    "        for book_ in seen: \n",
    "            # 3. 모든 책에 대해서 유사도를 더한 값을 계산 \n",
    "            # 343번째 책과 248의 유사도가 모두 결합된 유사도\n",
    "            total_cosine_sim += cosine_matrix[book_]\n",
    "            \n",
    "        # 4. 3에서 유사도가 가장 높은 순서대로 추출\n",
    "        sim_scores = [(bookid2book[book2id[i]], c) for i, c in enumerate(total_cosine_sim) if i not in seen] # 자기 자신을 제외한 영화들의 유사도 및 인덱스를 추출 \n",
    "        recs = sorted(sim_scores, key = lambda x: x[1], reverse=True)[0:300] # 유사도가 높은 순서대로 정렬 \n",
    "        for rec in recs: \n",
    "            if rec not in seen:\n",
    "                rec_list.append(rec)   \n",
    "        \n",
    "    # 그렇지 않으면 인기도 기반의 추천 \n",
    "    else: \n",
    "        seen = read_list1[read_list1['user_id'] == user]['unique'].values[0]\n",
    "        for rec in popular_rec_model[0:400]:\n",
    "            if rec not in seen:\n",
    "                rec_list.append(rec)\n",
    "                \n",
    "    total_rec_list[user] = rec_list[0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import six\n",
    "import math\n",
    "\n",
    "# https://github.com/kakao-arena/brunch-article-recommendation/blob/master/evaluate.py\n",
    "\n",
    "# 카카오 아레나에서 진행했던 평가함수 \n",
    "\n",
    "class evaluate():\n",
    "    def __init__(self, recs, gt, topn=100):\n",
    "        self.recs = recs\n",
    "        self.gt = gt \n",
    "        self.topn = topn \n",
    "        \n",
    "    def _ndcg(self):\n",
    "        Q, S = 0.0, 0.0\n",
    "        for u, seen in six.iteritems(self.gt):\n",
    "            seen = list(set(seen))\n",
    "            rec = self.recs.get(u, [])\n",
    "            if not rec or len(seen) == 0:\n",
    "                continue\n",
    "\n",
    "            dcg = 0.0\n",
    "            idcg = sum([1.0 / math.log(i + 2, 2) for i in range(min(len(seen), len(rec)))])\n",
    "            for i, r in enumerate(rec):\n",
    "                if r not in seen:\n",
    "                    continue\n",
    "                rank = i + 1\n",
    "                dcg += 1.0 / math.log(rank + 1, 2)\n",
    "            ndcg = dcg / idcg\n",
    "            S += ndcg\n",
    "            Q += 1\n",
    "        return S / Q\n",
    "\n",
    "\n",
    "    def _map(self):\n",
    "        n, ap = 0.0, 0.0\n",
    "        for u, seen in six.iteritems(self.gt):\n",
    "            seen = list(set(seen))\n",
    "            rec = self.recs.get(u, [])\n",
    "            if not rec or len(seen) == 0:\n",
    "                continue\n",
    "\n",
    "            _ap, correct = 0.0, 0.0\n",
    "            for i, r in enumerate(rec):\n",
    "                if r in seen:\n",
    "                    correct += 1\n",
    "                    _ap += (correct / (i + 1.0))\n",
    "            _ap /= min(len(seen), len(rec))\n",
    "            ap += _ap\n",
    "            n += 1.0\n",
    "        return ap / n\n",
    "\n",
    "\n",
    "    def _entropy_diversity(self): # -> 얼마나 다양한 책이 추천되어있는지, 사용자별로 추천한책이 다르면 높은값 ,개인화 정도를 측정하는 지표\n",
    "        sz = float(len(self.recs)) * self.topn\n",
    "        freq = {}\n",
    "        for u, rec in six.iteritems(self.recs):\n",
    "            for r in rec:\n",
    "                freq[r] = freq.get(r, 0) + 1\n",
    "        ent = -sum([v / sz * math.log(v / sz) for v in six.itervalues(freq)])\n",
    "        return ent\n",
    "    \n",
    "    def _evaluate(self):\n",
    "        print('MAP@%s: %s' % (self.topn, self._map()))\n",
    "        print('NDCG@%s: %s' % (self.topn, self._ndcg()))\n",
    "        print('EntDiv@%s: %s' % (self.topn, self._entropy_diversity()))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@200: 8.406195179554417e-05\n",
      "NDCG@200: 0.0008305515686697475\n",
      "EntDiv@200: 6.912056892078994\n"
     ]
    }
   ],
   "source": [
    "evaluate_func = evaluate(recs=total_rec_list, gt = gt, topn=200)\n",
    "evaluate_func._evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline 응용\n",
    " - 평점이 높은 글들을 우선적으로 추천 \n",
    " - 내가 좋아하는 작가의 글을 우선적으로 추천\n",
    " - 장바구니에 담긴 글과 작가의 글을 우선적으로 추천\n",
    " - 읽은 글의 시리즈글이 나오면 추천 (해리포타와 마법사의 돌 -> 비밀의 방)\n",
    " - 최신의 글을 추천\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Word2vec을 이용한 추천시스템 \n",
    " - Tag간의 유사도 \n",
    " - 제목간의 유사도 \n",
    " - 책의 읽은 순서를 통한 유사도 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[4893]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[8855]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[9049]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[3273]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[8072]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         unique\n",
       "user_id        \n",
       "1        [4893]\n",
       "2        [8855]\n",
       "3        [9049]\n",
       "4        [3273]\n",
       "5        [8072]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg = train.groupby(['user_id'])['book_id'].agg({'unique'})\n",
    "agg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# int형식은 Word2vec에서 학습이 안되어서 String으로 변경해줍니다. \n",
    "sentence = []\n",
    "for user_sentence in agg['unique'].values:\n",
    "    sentence.append(list(map(str, user_sentence)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2vec의 학습을 진행해줍니다. \n",
    "from gensim.models import Word2Vec\n",
    "embedding_model = Word2Vec(sentence, size=20, window = 5, \n",
    "                           min_count=1, workers=4, iter=200, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('9280', 0.8805376291275024),\n",
       " ('6471', 0.8421880006790161),\n",
       " ('3104', 0.8336400389671326),\n",
       " ('9910', 0.8256761431694031),\n",
       " ('4292', 0.8171288371086121),\n",
       " ('6447', 0.8113240599632263),\n",
       " ('5336', 0.805895984172821),\n",
       " ('9834', 0.8048577308654785),\n",
       " ('7716', 0.8037336468696594),\n",
       " ('8738', 0.7911606431007385)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model.wv.most_similar(positive=['4893'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4150fb6224cc42838d3b22463f2b26fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=53382.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## 전체 영화에 대해서 진행 \n",
    "total_rec_list = {}\n",
    "\n",
    "read_list = train.groupby(['user_id'])['book_id'].agg({'unique'}).reset_index()\n",
    "for user in tqdm(train['user_id'].unique()):\n",
    "    rec_list = []     \n",
    "    seen = read_list1[read_list1['user_id'] == user]['unique'].values[0]\n",
    "    word2vec_dict = {}\n",
    "    for book in seen: \n",
    "        for i in embedding_model.wv.most_similar(positive=[book], topn=300):\n",
    "            if i[0] not in seen: \n",
    "                if i[0] not in word2vec_dict.keys(): \n",
    "                    word2vec_dict[i[0]] = i[1]\n",
    "                else:\n",
    "                    word2vec_dict[i[0]] += i[1]\n",
    "                \n",
    "    rec_list = list(dict(sorted(word2vec_dict.items(), key = lambda x: x[1], reverse=True)).keys())\n",
    "    total_rec_list[user] = rec_list[0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@200: 0.06450800245365161\n",
      "NDCG@200: 0.19608417384043159\n",
      "EntDiv@200: 8.912385065578754\n"
     ]
    }
   ],
   "source": [
    "evaluate_func = evaluate(recs=total_rec_list, gt = gt, topn=200)\n",
    "evaluate_func._evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 태그를 통한 유사도 계산 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>tag_id</th>\n",
       "      <th>count</th>\n",
       "      <th>tag_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>30574</td>\n",
       "      <td>167697</td>\n",
       "      <td>to-read</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11305</td>\n",
       "      <td>37174</td>\n",
       "      <td>fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>11557</td>\n",
       "      <td>34173</td>\n",
       "      <td>favorites</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>8717</td>\n",
       "      <td>12986</td>\n",
       "      <td>currently-reading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>33114</td>\n",
       "      <td>12716</td>\n",
       "      <td>young-adult</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  book_id tag_id   count           tag_name\n",
       "0       1  30574  167697            to-read\n",
       "1       1  11305   37174            fantasy\n",
       "2       1  11557   34173          favorites\n",
       "3       1   8717   12986  currently-reading\n",
       "4       1  33114   12716        young-adult"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_tags.columns = ['book_id', 'tag_id', 'count']\n",
    "book_tags['book_id'] = book_tags['book_id'].astype(str)\n",
    "book_tags['tag_id'] = book_tags['tag_id'].astype(str)\n",
    "\n",
    "tags['tag_id'] = tags['tag_id'].astype(str)\n",
    "\n",
    "book_tags = pd.merge(book_tags, tags, how='left', on='tag_id')\n",
    "book_tags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>unique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[to-read, fantasy, favorites, currently-readin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>[to-read, favorites, fantasy, currently-readin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10006</td>\n",
       "      <td>[to-read, fiction, currently-reading, rory-gil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000751</td>\n",
       "      <td>[to-read, classics, childrens, fiction, curren...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10008056</td>\n",
       "      <td>[to-read, default, currently-reading, krimi, c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    book_id                                             unique\n",
       "0         1  [to-read, fantasy, favorites, currently-readin...\n",
       "1        10  [to-read, favorites, fantasy, currently-readin...\n",
       "2     10006  [to-read, fiction, currently-reading, rory-gil...\n",
       "3   1000751  [to-read, classics, childrens, fiction, curren...\n",
       "4  10008056  [to-read, default, currently-reading, krimi, c..."
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg = book_tags.groupby(['book_id'])['tag_name'].agg({'unique'}).reset_index()\n",
    "agg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 태그간의 유사도 계산 \n",
    "# int형식은 Word2vec에서 학습이 안되어서 String으로 변경해줍니다. \n",
    "sentence = []\n",
    "for user_sentence in agg['unique'].values:\n",
    "    sentence.append(list(map(str, user_sentence)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import doc2vec\n",
    "doc_vectorizer = doc2vec.Doc2Vec(\n",
    "    dm=0,            # PV-DBOW / default 1\n",
    "    dbow_words=1,    # w2v simultaneous with DBOW d2v / default 0\n",
    "    window=10,        # distance between the predicted word and context words\n",
    "    size=100,        # vector size\n",
    "    alpha=0.025,     # learning-rate\n",
    "    seed=1234,\n",
    "    min_count=5,    # ignore with freq lower\n",
    "    min_alpha=0.025, # min learning-rate\n",
    "    workers=4,   # multi cpu\n",
    "    hs = 1,          # hierar chical softmax / default 0\n",
    "    negative = 10   # negative sampling / default 5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "TaggedDocument = namedtuple('TaggedDocument', 'words tags')\n",
    "tagged_train_docs = [TaggedDocument(c, [d]) for c, d in agg[['unique', 'book_id']].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec(dbow+w,d100,n10,hs,w10,mc5,s0.001,t4)\n"
     ]
    }
   ],
   "source": [
    "doc_vectorizer.build_vocab(tagged_train_docs)\n",
    "print(str(doc_vectorizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8037f98054e34c3b93660189fc9daf6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "During Time: 395.4856255054474\n"
     ]
    }
   ],
   "source": [
    "# 벡터 문서 학습\n",
    "from time import time\n",
    "\n",
    "start = time()\n",
    "\n",
    "for epoch in tqdm(range(5)):\n",
    "    doc_vectorizer.train(tagged_train_docs, total_examples=doc_vectorizer.corpus_count, epochs=doc_vectorizer.iter)\n",
    "    doc_vectorizer.alpha -= 0.002 # decrease the learning rate\n",
    "    doc_vectorizer.min_alpha = doc_vectorizer.alpha # fix the learning rate, no decay\n",
    "\n",
    "#doc_vectorizer.train(tagged_train_docs, total_examples=doc_vectorizer.corpus_count, epochs=doc_vectorizer.iter)\n",
    "end = time()\n",
    "print(\"During Time: {}\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('136251', 0.8363346457481384),\n",
       " ('15881', 0.804844856262207),\n",
       " ('6', 0.7975798845291138),\n",
       " ('3', 0.7652629017829895),\n",
       " ('5', 0.7633213400840759),\n",
       " ('862041', 0.7382413744926453),\n",
       " ('10', 0.7181618213653564),\n",
       " ('2', 0.7108365297317505),\n",
       " ('99298', 0.669237494468689),\n",
       " ('100464', 0.6507803201675415),\n",
       " ('1317181', 0.6394864916801453),\n",
       " ('28187', 0.6334356069564819),\n",
       " ('6294', 0.6255398988723755),\n",
       " ('111450', 0.6163853406906128),\n",
       " ('93724', 0.6107273101806641),\n",
       " ('2120932', 0.6099746823310852),\n",
       " ('3950967', 0.6093368530273438),\n",
       " ('28195', 0.6074846982955933),\n",
       " ('9520360', 0.6058236956596375),\n",
       " ('28194', 0.603295624256134)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_vectorizer.docvecs.most_similar('1', topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4893</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>8855</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9049</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3273</td>\n",
       "      <td>Moloka'i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>8072</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id book_id     title\n",
       "0        1    4893       NaN\n",
       "1        2    8855       NaN\n",
       "2        3    9049       NaN\n",
       "3        4    3273  Moloka'i\n",
       "4        5    8072       NaN"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tag 정보가 있는 책이 있고 아닌 책이 있어서 해당 책만 추출 \n",
    "agg['type'] = '1'\n",
    "train = pd.merge(train, agg, how='left', on='book_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af6e9367261542eaa038ce5859ab779d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=53382.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## 전체 영화에 대해서 진행 \n",
    "total_rec_list = {}\n",
    "\n",
    "read_list1 = train.groupby(['user_id'])['book_id'].agg({'unique'}).reset_index()\n",
    "read_list2 = train[train['type'] == '1'].groupby(['user_id'])['book_id'].agg({'unique'}).reset_index()\n",
    "for user in tqdm(train['user_id'].unique()):\n",
    "    rec_list = []\n",
    "    if user in read_list2['user_id'].unique():\n",
    "        seen = read_list2[read_list2['user_id'] == user]['unique'].values[0]\n",
    "        doc2vec_dict = {}\n",
    "        for book in seen: \n",
    "            for i in doc_vectorizer.docvecs.most_similar(positive=[book], topn=300): \n",
    "                if i[0] not in doc2vec_dict.keys(): \n",
    "                    doc2vec_dict[i[0]] = i[1]\n",
    "                else:\n",
    "                    doc2vec_dict[i[0]] += i[1]\n",
    "\n",
    "        rec_list = list(dict(sorted(doc2vec_dict.items(), key = lambda x: x[1], reverse=True)).keys())\n",
    "    else:\n",
    "        \n",
    "        seen = read_list1[read_list1['user_id'] == user]['unique'].values[0]\n",
    "        for rec in popular_rec_model[0:300]:\n",
    "            if rec not in seen:\n",
    "                rec_list.append(rec)\n",
    "    total_rec_list[user] = rec_list[0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@200: 0.00016434541519772954\n",
      "NDCG@200: 0.001643791944974857\n",
      "EntDiv@200: 6.991381104877936\n"
     ]
    }
   ],
   "source": [
    "evaluate_func = evaluate(recs=total_rec_list, gt = gt, topn=200)\n",
    "evaluate_func._evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
